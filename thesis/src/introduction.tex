\chapter{Introduction}
\label{introduction}

Today's industrialised society has been been vastly shaped by information and communication technologies and the demand for always faster data processing rates is increasing at an ever-growing pace. This motivates the research and development of new computation technologies that would provide alternatives to classical silicon-based computers. Based on the theoretical framework developed by Shannon \cite{shannon1948mathematical}, Landauer showed that \say{Information is physical} \cite{Landauer1991}. Loosely speaking, this suggests that the abstract notion of information needs to rely on some kind of physical encoding and processing in order to exist. However, there is no physical law imposing that information can only be processed on silicon or biological carbon based devices. These  materials are just two different instances of \textit{computronium}, which is a term coined by Toffoli and Margolus \cite{amato1991speculating} to designate any substrate able to compute. These elements suggest that trying to develop innovative new information technologies is a legitimate endeavour.\\

Optical computers have been investigated for many years. Because they use light as information carrier, their characteristic speed is inherently close to the maximum one allowed in our Universe. In their article \cite{Caulfield2010} Caulfield and Dolev envision them as the natural choice when it comes to finding the computation paradigm of tomorrow because they claim that optical computers can be fast, energy efficient, and generate less heat. They argue that silicon-based devices are reaching their physical limits in terms of bandwidth and that great improvements have been realised as far as all optical boolean logic is concerned. Moreover, they point out the fact that optical computers do not have to mimic the computation logic of classical computers, and that future designs should take advantage of physical properties specific to light. The practical study of such a device is the main goal of this work.\\

In this master thesis, the experimental study of the interferometric stabilisation of a fibre-based optical reservoir computer is tackled. Its first part introduces the concept of reservoir computing, which is a subclass of recurrent neural networks achieving state of the art performances in tasks involving processing of time dependent data. Reservoir computers differ from classical neural networks by the fact when they are being trained, they only require their output weights to be updated, which makes them computationally attractive. The mathematical model governing the time evolution of a reservoir computer imposes so little conditions that it is possible to reproduce its dynamics using a physical system other than classical computers. The literature shows that this has already been done a couple of times using optical setups, but so far, only a time division multiplexing of the neurons has been implemented, which limits the processing speed.\\

In the second chapter, an innovative scheme of a fibre-based photonic reservoir computer relying on wavelength division multiplexing of the neurons is presented. Each of the neurons is encoded in a different wavelength of an electric field evolving inside a fibre loop cavity. The wavelength mixing of the different neurons is performed by a phase modulator. However, because of the physical properties of phase modulators, only a few neurons can be used at the same time. The main advantage of this new sheme is a theoretical increase in the processing speed, because multiplexing the neurons in wavelength instead of time allows the input data to reach all the neurons simultaneously.\\


The third part of the thesis is devoted to the experimental characterisation of the stabilisation performances of the optical cavity used as the reservoir computer. The phase acquired by the electric field each time it goes around the cavity is an important parameter which has an influence on the performances of the reservoir computer and that should be kept under control. The classical cavity stabilisation technique uses the power reflected by the cavity, which is a feature linked to interferometry, to estimate the phase and uses well known control theory methods to regulate it. However, in this experiment, new difficulties arise due to the fact that the light signal used to stabilise the cavity happens to be modulated in intensity because it carries the data to be processed. A possible solution to overcome this issue is to use the Pound-Drever-Hall stabilisation technique which is a powerful tool allowing to stabilise cavities with a greater precision. Its main advantage over the classical technique is that, by phase modulating the laser wave and by performing some electronic post-processing, the signal it measures conveys more information about the phase inside the cavity and allows to carry out a better regulation. This stabilisation technique has been implemented on the experiment, and the quality of the stabilisation has been assessed for different Pound-Drever-Hall parameters in order to determine for which ones the cavity is the most likely to be stable enough to operate as a reservoir computer.\\


The last part of this work comes back to the main results encountered throughout this year of research, and concludes by indicating which experimental parameters should be included in future works in order to refine the data that have been characterised.







